{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creativity assessment scoring by Fine tuning Bert- English.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3Lgq7TeWTSr7FEUfsGoYX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8083bdf04463459abe0cd22f0acc3acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52a391fe6dff4759a56319669d1d873e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c98b4a7602d4aa18a0b9d48b0736a8a",
              "IPY_MODEL_222008db5b094c7f8a57cafd3a05f42a"
            ]
          }
        },
        "52a391fe6dff4759a56319669d1d873e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c98b4a7602d4aa18a0b9d48b0736a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7237e6bb8f4a41c88ee9f46a8ea3924c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a71bde8abd64e82bb6b6c39c6fffc6d"
          }
        },
        "222008db5b094c7f8a57cafd3a05f42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06855a54f8b64b48a6c7e2a40c9e812b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.06kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d76af2e0b28a4e24a8f6b47ed67864e8"
          }
        },
        "7237e6bb8f4a41c88ee9f46a8ea3924c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a71bde8abd64e82bb6b6c39c6fffc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06855a54f8b64b48a6c7e2a40c9e812b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d76af2e0b28a4e24a8f6b47ed67864e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "634ef4f29e804cd4916543da4a72954f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7530178501154c549acf27d34b53c2f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_99786c3d08b24cfd8586b7b4afdd79d5",
              "IPY_MODEL_cd5fb132528a43daa0a59320ef076bb8"
            ]
          }
        },
        "7530178501154c549acf27d34b53c2f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99786c3d08b24cfd8586b7b4afdd79d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb8f18a2368540648f6f8a5e94b6f284",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0acfbf0755441b6b4495178cac4bbc9"
          }
        },
        "cd5fb132528a43daa0a59320ef076bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f088daa1ffc4642adea09093d2a7674",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:19&lt;00:00, 22.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9d834f592d94a148852f9df97a03672"
          }
        },
        "eb8f18a2368540648f6f8a5e94b6f284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0acfbf0755441b6b4495178cac4bbc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f088daa1ffc4642adea09093d2a7674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9d834f592d94a148852f9df97a03672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sundaravelss/Creativity-Assessment-Scoring-using-NLP/blob/main/Creativity_assessment_scoring_by_Fine_tuning_Bert_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEOSMl9wrIpY",
        "outputId": "f7143968-8929-4b0a-ae39-600cca15e590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#checking for gpu instance\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR7Cw-w4rUK4",
        "outputId": "94cfe358-0800-4de3-d32a-6cc469708b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#setting device to use gpu\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhLu5xGUrZea",
        "outputId": "9df49f44-5735-421f-99a0-412101aecb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR1erIKwrh6u",
        "outputId": "3931e93b-a2fa-4a26-bc24-0de23d84c4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "#loading the dataset\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_excel('./final_data_english.xlsx')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Collect water</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>parachute</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sun protection.</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>against rain</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>protection from the rain</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134</th>\n",
              "      <td>1134</td>\n",
              "      <td>hat holder</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>1135</td>\n",
              "      <td>Kite</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1136</th>\n",
              "      <td>1136</td>\n",
              "      <td>Wall decoration</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1137</th>\n",
              "      <td>1137</td>\n",
              "      <td>pole</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1138</th>\n",
              "      <td>1138</td>\n",
              "      <td>fishing rod</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1139 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                  sentence  label\n",
              "0              0             Collect water    3.0\n",
              "1              1                 parachute    4.0\n",
              "2              2           Sun protection.    2.0\n",
              "3              3              against rain    1.0\n",
              "4              4  protection from the rain    1.0\n",
              "...          ...                       ...    ...\n",
              "1134        1134                hat holder    4.0\n",
              "1135        1135                      Kite    9.0\n",
              "1136        1136           Wall decoration    4.0\n",
              "1137        1137                      pole    4.0\n",
              "1138        1138               fishing rod    4.0\n",
              "\n",
              "[1139 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2KECujmtkuG",
        "outputId": "642d3d50-58ec-4574-bb71-af05a9280cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "#counting number of unique labels(scores here)\n",
        "print('no. of unique values:',len(df.label.unique()))\n",
        "df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of unique values: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0    178\n",
              "3.0    173\n",
              "3.5    113\n",
              "5.0    100\n",
              "2.5     92\n",
              "4.5     87\n",
              "2.0     70\n",
              "6.0     68\n",
              "1.5     60\n",
              "1.0     60\n",
              "5.5     45\n",
              "6.5     34\n",
              "7.0     32\n",
              "8.0     14\n",
              "7.5     10\n",
              "8.5      2\n",
              "9.0      1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qazuug0qr8pb"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHxYtyaz90ux",
        "outputId": "3305ae14-880e-43cd-c8c4-0c0ee48bfdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 4., 2., ..., 4., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_xmuFfPsIK8",
        "outputId": "425e1850-4943-4078-e46c-28b7cc00804d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrPmJpHcsN3Q",
        "outputId": "04b7da8c-f866-4710-ecad-df39104a221e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#View tokenized sentence\n",
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Collect water\n",
            "Tokenized:  ['collect', 'water']\n",
            "Token IDs:  [8145, 2300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmOfWnqfsmic",
        "outputId": "30a6e004-f271-4bf8-9f16-c05a706309fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#getting maximum length of the sentence in the dataset\n",
        "length=[]\n",
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    #print(len(input_ids))\n",
        "    #adding length to the list to plot it\n",
        "    length.append(len(input_ids))\n",
        "    max_len = max(max_len,len(input_ids))\n",
        "\n",
        "print('Max sentence tokens: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence tokens:  50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxXyeXCErBlf",
        "outputId": "2c25eabb-1b43-4eb9-dc4f-3b0ebf27b1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(length)\n",
        "\n",
        "#sns.distplot(length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f19e83c8a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWGwW9CT8nMq",
        "outputId": "f3e12c7d-58dd-4f57-a4da-8897c6b51a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#maximum number of words in a sentence\n",
        "df.sentence.map(len).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUAiVeKs-UjH",
        "outputId": "37d0f04c-6537-4640-b13c-5054cb72e693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "for sent in sentences:\n",
        "  if(len(sent)==236):\n",
        "    print('The sentence which has the maximum number of words is:',sent, len(sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentence which has the maximum number of words is: small rain recovery by reversing the umbrella and adding a pipe use (possibility to stack in cascade to increase the capacity). A sports equipment to work flexibility (use the handle for example catch the foot and allow to pull the leg) 236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgkvFuHl-cWa",
        "outputId": "fe7f307a-6a46-4803-ac07-9b5f0ac3d800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, add_special_tokens = True, max_length = 15,pad_to_max_length = True,return_attention_mask = True, return_tensors = 'pt',truncation=True )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Collect water\n",
            "Token IDs: tensor([ 101, 8145, 2300,  102,    0,    0,    0,    0,    0,    0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuJIPvY6AQcS",
        "outputId": "296a9b67-9c6f-4bbc-b951-03909b7614a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#changing labels to tensor and dtype as float for regression and long for classification\n",
        "labels = torch.tensor(labels,dtype=torch.float)\n",
        "labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_OuihSeSRUo",
        "outputId": "669f7803-c767-4bb5-e2d4-f8f7cf18e36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#attention mask (simply differentiates padding from non-padding).\n",
        "attention_masks[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88G6xnjQB3VG",
        "outputId": "70355340-e425-4b3f-9279-a63372b846d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,025 training samples\n",
            "  114 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytOwgnsvRpt5"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#hyperparameter 16 or 32\n",
        "batch_size = 16\n",
        "#dataloader\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size )\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF-djsMeU55k",
        "outputId": "e66ff2d5-eea7-40f6-f5cc-7e2e8e485bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8083bdf04463459abe0cd22f0acc3acc",
            "52a391fe6dff4759a56319669d1d873e",
            "1c98b4a7602d4aa18a0b9d48b0736a8a",
            "222008db5b094c7f8a57cafd3a05f42a",
            "7237e6bb8f4a41c88ee9f46a8ea3924c",
            "9a71bde8abd64e82bb6b6c39c6fffc6d",
            "06855a54f8b64b48a6c7e2a40c9e812b",
            "d76af2e0b28a4e24a8f6b47ed67864e8",
            "634ef4f29e804cd4916543da4a72954f",
            "7530178501154c549acf27d34b53c2f0",
            "99786c3d08b24cfd8586b7b4afdd79d5",
            "cd5fb132528a43daa0a59320ef076bb8",
            "eb8f18a2368540648f6f8a5e94b6f284",
            "e0acfbf0755441b6b4495178cac4bbc9",
            "0f088daa1ffc4642adea09093d2a7674",
            "f9d834f592d94a148852f9df97a03672"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 1, # The number of output labels--10 (1 to 9) or --17 (if 0.5 is to be included.e.g,1,1.5,2..) for classification\n",
        "                    #num_labels=1 for regression task   \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8083bdf04463459abe0cd22f0acc3acc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "634ef4f29e804cd4916543da4a72954f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiVAybuBU7b8"
      },
      "source": [
        "#optimizing with adamw\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSHI_fXkqksx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM38VX73rYGc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels for classification\n",
        "'''def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)'''\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels for regression\n",
        "def flat_accuracy(preds,labels):\n",
        "  labels_flat=labels.flatten()  #flattening the labels\n",
        "  labels_flat=np.round(labels_flat)  #rounding to 0 decimal points\n",
        "  preds_flat=preds.flatten()     #flattening the predictions\n",
        "  preds_flat=np.round(preds_flat)\n",
        "  #print(labels_flat)\n",
        "  #print(preds_flat)\n",
        "  length=len(labels_flat)\n",
        "  accuracy=np.sum(preds_flat==labels_flat)/length\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE4l1vZ7u_4z"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECON08Faz3p5",
        "outputId": "a7aa2bda-7a58-449c-8c5b-d44221197570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "#looking at a batch in dataloader\n",
        "#first index([0]) has the input_its, 2nd([0]) attention masks and 3rd labels\n",
        "for batch in train_dataloader:\n",
        "  print(batch[0],batch[2])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  5047,   102,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  6512,   102,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  3898,   102,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  3742, 28972,   102,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  2004,  1037, 11942,   102,     0,     0,     0,     0,     0],\n",
            "        [  101, 11473,   102,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  2191,  1037, 16967,   102,     0,     0,     0,     0,     0],\n",
            "        [  101,  2019,  4874,  2008,  2097,  2022,  4844,   102,     0,     0],\n",
            "        [  101,  3229,  6499,  7442,  2806,   102,     0,     0,     0,     0],\n",
            "        [  101,  4690,   102,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101, 12977,   102,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  5418,  2063,   102,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  2114,  1996,  3103,   102,     0,     0,     0,     0,     0],\n",
            "        [  101,  5943,  5997,   102,     0,     0,     0,     0,     0,     0],\n",
            "        [  101, 14658,   102,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  6723,  6802,  5200,   102,     0,     0,     0,     0,     0]]) tensor([2.0000, 3.0000, 2.0000, 4.0000, 3.0000, 3.5000, 4.0000, 4.5000, 3.5000,\n",
            "        2.0000, 1.5000, 3.5000, 2.0000, 8.5000, 6.5000, 4.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZQqG-LQvgZU",
        "outputId": "f27663e5-6ba1-4f99-ceaa-28f87ebffc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#CUDA_LAUNCH_BLOCKING=\"1\"\n",
        "import random\n",
        "import numpy as np\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    #Training\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0 to prevent exploding gradient\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # validation\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "      \n",
        "        #input ids\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        #attention mask\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        #labels\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        print('the logits',logits)\n",
        "        print('label',label_ids)\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        #print(logits)\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.74\n",
            "  Training epcoh took: 0:00:05\n",
            "\n",
            "Running Validation...\n",
            "the logits [[3.609791 ]\n",
            " [0.9706271]\n",
            " [2.7581224]\n",
            " [4.642426 ]\n",
            " [1.5384126]\n",
            " [5.1772976]\n",
            " [4.8013234]\n",
            " [3.7125468]\n",
            " [2.1318722]\n",
            " [4.2635813]\n",
            " [5.030517 ]\n",
            " [1.4553757]\n",
            " [4.400973 ]\n",
            " [5.6623096]\n",
            " [2.375461 ]\n",
            " [3.0641606]]\n",
            "label [4.  1.  3.5 3.  2.5 2.  6.  5.5 2.  4.  5.  1.5 6.5 5.  2.5 4. ]\n",
            "[4. 1. 4. 3. 2. 2. 6. 6. 2. 4. 5. 2. 6. 5. 2. 4.]\n",
            "[4. 1. 3. 5. 2. 5. 5. 4. 2. 4. 5. 1. 4. 6. 2. 3.]\n",
            "the logits [[3.8311296]\n",
            " [5.4108567]\n",
            " [2.793728 ]\n",
            " [3.7803195]\n",
            " [2.3469794]\n",
            " [5.8129783]\n",
            " [1.5384126]\n",
            " [5.1003704]\n",
            " [4.6387434]\n",
            " [4.173278 ]\n",
            " [5.184827 ]\n",
            " [5.1445985]\n",
            " [5.1961374]\n",
            " [5.529098 ]\n",
            " [2.3469794]\n",
            " [4.2437944]]\n",
            "label [4.  4.  3.  3.5 2.5 4.5 1.5 8.  5.  4.  4.5 4.  4.  6.  2.5 5. ]\n",
            "[4. 4. 3. 4. 2. 4. 2. 8. 5. 4. 4. 4. 4. 6. 2. 5.]\n",
            "[4. 5. 3. 4. 2. 6. 2. 5. 5. 4. 5. 5. 5. 6. 2. 4.]\n",
            "the logits [[5.2560706]\n",
            " [2.1012447]\n",
            " [2.0855057]\n",
            " [4.2635813]\n",
            " [5.333635 ]\n",
            " [4.2437944]\n",
            " [3.0745964]\n",
            " [1.0560193]\n",
            " [2.7823758]\n",
            " [5.4462743]\n",
            " [5.125124 ]\n",
            " [3.288515 ]\n",
            " [4.538252 ]\n",
            " [5.7403083]\n",
            " [4.2635813]\n",
            " [5.1501675]]\n",
            "label [4.  2.5 2.  4.  5.  5.5 2.5 1.  3.  6.  4.5 3.  4.  5.  4.  3. ]\n",
            "[4. 2. 2. 4. 5. 6. 2. 1. 3. 6. 4. 3. 4. 5. 4. 3.]\n",
            "[5. 2. 2. 4. 5. 4. 3. 1. 3. 5. 5. 3. 5. 6. 4. 5.]\n",
            "the logits [[3.8995864]\n",
            " [3.7014825]\n",
            " [2.910807 ]\n",
            " [4.066693 ]\n",
            " [5.605818 ]\n",
            " [2.3204975]\n",
            " [2.9307563]\n",
            " [5.6870008]\n",
            " [1.220434 ]\n",
            " [5.7410555]\n",
            " [3.1930254]\n",
            " [1.4553757]\n",
            " [4.7886677]\n",
            " [2.6110704]\n",
            " [5.6839666]\n",
            " [4.2635813]]\n",
            "label [6.  2.  3.  3.5 3.5 2.5 2.5 7.  1.  4.  4.  1.5 6.5 5.  7.  4. ]\n",
            "[6. 2. 3. 4. 4. 2. 2. 7. 1. 4. 4. 2. 6. 5. 7. 4.]\n",
            "[4. 4. 3. 4. 6. 2. 3. 6. 1. 6. 3. 1. 5. 3. 6. 4.]\n",
            "the logits [[4.42121  ]\n",
            " [4.2635813]\n",
            " [1.967767 ]\n",
            " [5.601151 ]\n",
            " [5.4462743]\n",
            " [1.77587  ]\n",
            " [2.2674165]\n",
            " [1.0118765]\n",
            " [4.202923 ]\n",
            " [4.2635813]\n",
            " [5.473537 ]\n",
            " [1.5653011]\n",
            " [1.4553757]\n",
            " [4.7137694]\n",
            " [4.902739 ]\n",
            " [2.7823758]]\n",
            "label [4.  4.  1.  2.5 5.5 2.5 2.5 1.  4.  4.  8.  1.  1.5 3.5 5.  3. ]\n",
            "[4. 4. 1. 2. 6. 2. 2. 1. 4. 4. 8. 1. 2. 4. 5. 3.]\n",
            "[4. 4. 2. 6. 5. 2. 2. 1. 4. 4. 5. 2. 1. 5. 5. 3.]\n",
            "the logits [[2.7823758]\n",
            " [5.6354623]\n",
            " [4.2007937]\n",
            " [1.4553757]\n",
            " [3.37885  ]\n",
            " [3.37885  ]\n",
            " [5.6479764]\n",
            " [2.1318722]\n",
            " [3.8560057]\n",
            " [2.4535918]\n",
            " [4.7646394]\n",
            " [2.7823758]\n",
            " [1.3539591]\n",
            " [4.656163 ]\n",
            " [3.8722355]\n",
            " [2.1012447]]\n",
            "label [3.  4.5 4.  1.5 3.5 3.  5.  2.  2.  2.5 4.  3.  1.  3.5 6.  2.5]\n",
            "[3. 4. 4. 2. 4. 3. 5. 2. 2. 2. 4. 3. 1. 4. 6. 2.]\n",
            "[3. 6. 4. 1. 3. 3. 6. 2. 4. 2. 5. 3. 1. 5. 4. 2.]\n",
            "the logits [[3.1604373]\n",
            " [5.524593 ]\n",
            " [4.744967 ]\n",
            " [5.5648665]\n",
            " [5.628711 ]\n",
            " [4.9508133]\n",
            " [4.0238414]\n",
            " [4.2635813]\n",
            " [4.3991017]\n",
            " [5.3947916]\n",
            " [2.8584855]\n",
            " [5.7847633]\n",
            " [4.6514416]\n",
            " [4.647722 ]\n",
            " [2.8775783]\n",
            " [2.3202627]]\n",
            "label [3.  3.5 3.5 3.5 6.5 3.5 3.5 4.  3.  4.5 2.5 5.5 4.5 3.  4.5 2.5]\n",
            "[3. 4. 4. 4. 6. 4. 4. 4. 3. 4. 2. 6. 4. 3. 4. 2.]\n",
            "[3. 6. 5. 6. 6. 5. 4. 4. 4. 5. 3. 6. 5. 5. 3. 2.]\n",
            "the logits [[5.28323  ]\n",
            " [3.1924317]]\n",
            "label [3.  4.5]\n",
            "[3. 4.]\n",
            "[5. 3.]\n",
            "  Accuracy: 0.41\n",
            "  Validation Loss: 1.47\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:00:05\n",
            "\n",
            "Running Validation...\n",
            "the logits [[3.609791 ]\n",
            " [0.9706271]\n",
            " [2.7581224]\n",
            " [4.642426 ]\n",
            " [1.5384126]\n",
            " [5.1772976]\n",
            " [4.8013234]\n",
            " [3.7125468]\n",
            " [2.1318722]\n",
            " [4.2635813]\n",
            " [5.030517 ]\n",
            " [1.4553757]\n",
            " [4.400973 ]\n",
            " [5.6623096]\n",
            " [2.375461 ]\n",
            " [3.0641606]]\n",
            "label [4.  1.  3.5 3.  2.5 2.  6.  5.5 2.  4.  5.  1.5 6.5 5.  2.5 4. ]\n",
            "[4. 1. 4. 3. 2. 2. 6. 6. 2. 4. 5. 2. 6. 5. 2. 4.]\n",
            "[4. 1. 3. 5. 2. 5. 5. 4. 2. 4. 5. 1. 4. 6. 2. 3.]\n",
            "the logits [[3.8311296]\n",
            " [5.4108567]\n",
            " [2.793728 ]\n",
            " [3.7803195]\n",
            " [2.3469794]\n",
            " [5.8129783]\n",
            " [1.5384126]\n",
            " [5.1003704]\n",
            " [4.6387434]\n",
            " [4.173278 ]\n",
            " [5.184827 ]\n",
            " [5.1445985]\n",
            " [5.1961374]\n",
            " [5.529098 ]\n",
            " [2.3469794]\n",
            " [4.2437944]]\n",
            "label [4.  4.  3.  3.5 2.5 4.5 1.5 8.  5.  4.  4.5 4.  4.  6.  2.5 5. ]\n",
            "[4. 4. 3. 4. 2. 4. 2. 8. 5. 4. 4. 4. 4. 6. 2. 5.]\n",
            "[4. 5. 3. 4. 2. 6. 2. 5. 5. 4. 5. 5. 5. 6. 2. 4.]\n",
            "the logits [[5.2560706]\n",
            " [2.1012447]\n",
            " [2.0855057]\n",
            " [4.2635813]\n",
            " [5.333635 ]\n",
            " [4.2437944]\n",
            " [3.0745964]\n",
            " [1.0560193]\n",
            " [2.7823758]\n",
            " [5.4462743]\n",
            " [5.125124 ]\n",
            " [3.288515 ]\n",
            " [4.538252 ]\n",
            " [5.7403083]\n",
            " [4.2635813]\n",
            " [5.1501675]]\n",
            "label [4.  2.5 2.  4.  5.  5.5 2.5 1.  3.  6.  4.5 3.  4.  5.  4.  3. ]\n",
            "[4. 2. 2. 4. 5. 6. 2. 1. 3. 6. 4. 3. 4. 5. 4. 3.]\n",
            "[5. 2. 2. 4. 5. 4. 3. 1. 3. 5. 5. 3. 5. 6. 4. 5.]\n",
            "the logits [[3.8995864]\n",
            " [3.7014825]\n",
            " [2.910807 ]\n",
            " [4.066693 ]\n",
            " [5.605818 ]\n",
            " [2.3204975]\n",
            " [2.9307563]\n",
            " [5.6870008]\n",
            " [1.220434 ]\n",
            " [5.7410555]\n",
            " [3.1930254]\n",
            " [1.4553757]\n",
            " [4.7886677]\n",
            " [2.6110704]\n",
            " [5.6839666]\n",
            " [4.2635813]]\n",
            "label [6.  2.  3.  3.5 3.5 2.5 2.5 7.  1.  4.  4.  1.5 6.5 5.  7.  4. ]\n",
            "[6. 2. 3. 4. 4. 2. 2. 7. 1. 4. 4. 2. 6. 5. 7. 4.]\n",
            "[4. 4. 3. 4. 6. 2. 3. 6. 1. 6. 3. 1. 5. 3. 6. 4.]\n",
            "the logits [[4.42121  ]\n",
            " [4.2635813]\n",
            " [1.967767 ]\n",
            " [5.601151 ]\n",
            " [5.4462743]\n",
            " [1.77587  ]\n",
            " [2.2674165]\n",
            " [1.0118765]\n",
            " [4.202923 ]\n",
            " [4.2635813]\n",
            " [5.473537 ]\n",
            " [1.5653011]\n",
            " [1.4553757]\n",
            " [4.7137694]\n",
            " [4.902739 ]\n",
            " [2.7823758]]\n",
            "label [4.  4.  1.  2.5 5.5 2.5 2.5 1.  4.  4.  8.  1.  1.5 3.5 5.  3. ]\n",
            "[4. 4. 1. 2. 6. 2. 2. 1. 4. 4. 8. 1. 2. 4. 5. 3.]\n",
            "[4. 4. 2. 6. 5. 2. 2. 1. 4. 4. 5. 2. 1. 5. 5. 3.]\n",
            "the logits [[2.7823758]\n",
            " [5.6354623]\n",
            " [4.2007937]\n",
            " [1.4553757]\n",
            " [3.37885  ]\n",
            " [3.37885  ]\n",
            " [5.6479764]\n",
            " [2.1318722]\n",
            " [3.8560057]\n",
            " [2.4535918]\n",
            " [4.7646394]\n",
            " [2.7823758]\n",
            " [1.3539591]\n",
            " [4.656163 ]\n",
            " [3.8722355]\n",
            " [2.1012447]]\n",
            "label [3.  4.5 4.  1.5 3.5 3.  5.  2.  2.  2.5 4.  3.  1.  3.5 6.  2.5]\n",
            "[3. 4. 4. 2. 4. 3. 5. 2. 2. 2. 4. 3. 1. 4. 6. 2.]\n",
            "[3. 6. 4. 1. 3. 3. 6. 2. 4. 2. 5. 3. 1. 5. 4. 2.]\n",
            "the logits [[3.1604373]\n",
            " [5.524593 ]\n",
            " [4.744967 ]\n",
            " [5.5648665]\n",
            " [5.628711 ]\n",
            " [4.9508133]\n",
            " [4.0238414]\n",
            " [4.2635813]\n",
            " [4.3991017]\n",
            " [5.3947916]\n",
            " [2.8584855]\n",
            " [5.7847633]\n",
            " [4.6514416]\n",
            " [4.647722 ]\n",
            " [2.8775783]\n",
            " [2.3202627]]\n",
            "label [3.  3.5 3.5 3.5 6.5 3.5 3.5 4.  3.  4.5 2.5 5.5 4.5 3.  4.5 2.5]\n",
            "[3. 4. 4. 4. 6. 4. 4. 4. 3. 4. 2. 6. 4. 3. 4. 2.]\n",
            "[3. 6. 5. 6. 6. 5. 4. 4. 4. 5. 3. 6. 5. 5. 3. 2.]\n",
            "the logits [[5.28323  ]\n",
            " [3.1924317]]\n",
            "label [3.  4.5]\n",
            "[3. 4.]\n",
            "[5. 3.]\n",
            "  Accuracy: 0.41\n",
            "  Validation Loss: 1.47\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:00:05\n",
            "\n",
            "Running Validation...\n",
            "the logits [[3.609791 ]\n",
            " [0.9706271]\n",
            " [2.7581224]\n",
            " [4.642426 ]\n",
            " [1.5384126]\n",
            " [5.1772976]\n",
            " [4.8013234]\n",
            " [3.7125468]\n",
            " [2.1318722]\n",
            " [4.2635813]\n",
            " [5.030517 ]\n",
            " [1.4553757]\n",
            " [4.400973 ]\n",
            " [5.6623096]\n",
            " [2.375461 ]\n",
            " [3.0641606]]\n",
            "label [4.  1.  3.5 3.  2.5 2.  6.  5.5 2.  4.  5.  1.5 6.5 5.  2.5 4. ]\n",
            "[4. 1. 4. 3. 2. 2. 6. 6. 2. 4. 5. 2. 6. 5. 2. 4.]\n",
            "[4. 1. 3. 5. 2. 5. 5. 4. 2. 4. 5. 1. 4. 6. 2. 3.]\n",
            "the logits [[3.8311296]\n",
            " [5.4108567]\n",
            " [2.793728 ]\n",
            " [3.7803195]\n",
            " [2.3469794]\n",
            " [5.8129783]\n",
            " [1.5384126]\n",
            " [5.1003704]\n",
            " [4.6387434]\n",
            " [4.173278 ]\n",
            " [5.184827 ]\n",
            " [5.1445985]\n",
            " [5.1961374]\n",
            " [5.529098 ]\n",
            " [2.3469794]\n",
            " [4.2437944]]\n",
            "label [4.  4.  3.  3.5 2.5 4.5 1.5 8.  5.  4.  4.5 4.  4.  6.  2.5 5. ]\n",
            "[4. 4. 3. 4. 2. 4. 2. 8. 5. 4. 4. 4. 4. 6. 2. 5.]\n",
            "[4. 5. 3. 4. 2. 6. 2. 5. 5. 4. 5. 5. 5. 6. 2. 4.]\n",
            "the logits [[5.2560706]\n",
            " [2.1012447]\n",
            " [2.0855057]\n",
            " [4.2635813]\n",
            " [5.333635 ]\n",
            " [4.2437944]\n",
            " [3.0745964]\n",
            " [1.0560193]\n",
            " [2.7823758]\n",
            " [5.4462743]\n",
            " [5.125124 ]\n",
            " [3.288515 ]\n",
            " [4.538252 ]\n",
            " [5.7403083]\n",
            " [4.2635813]\n",
            " [5.1501675]]\n",
            "label [4.  2.5 2.  4.  5.  5.5 2.5 1.  3.  6.  4.5 3.  4.  5.  4.  3. ]\n",
            "[4. 2. 2. 4. 5. 6. 2. 1. 3. 6. 4. 3. 4. 5. 4. 3.]\n",
            "[5. 2. 2. 4. 5. 4. 3. 1. 3. 5. 5. 3. 5. 6. 4. 5.]\n",
            "the logits [[3.8995864]\n",
            " [3.7014825]\n",
            " [2.910807 ]\n",
            " [4.066693 ]\n",
            " [5.605818 ]\n",
            " [2.3204975]\n",
            " [2.9307563]\n",
            " [5.6870008]\n",
            " [1.220434 ]\n",
            " [5.7410555]\n",
            " [3.1930254]\n",
            " [1.4553757]\n",
            " [4.7886677]\n",
            " [2.6110704]\n",
            " [5.6839666]\n",
            " [4.2635813]]\n",
            "label [6.  2.  3.  3.5 3.5 2.5 2.5 7.  1.  4.  4.  1.5 6.5 5.  7.  4. ]\n",
            "[6. 2. 3. 4. 4. 2. 2. 7. 1. 4. 4. 2. 6. 5. 7. 4.]\n",
            "[4. 4. 3. 4. 6. 2. 3. 6. 1. 6. 3. 1. 5. 3. 6. 4.]\n",
            "the logits [[4.42121  ]\n",
            " [4.2635813]\n",
            " [1.967767 ]\n",
            " [5.601151 ]\n",
            " [5.4462743]\n",
            " [1.77587  ]\n",
            " [2.2674165]\n",
            " [1.0118765]\n",
            " [4.202923 ]\n",
            " [4.2635813]\n",
            " [5.473537 ]\n",
            " [1.5653011]\n",
            " [1.4553757]\n",
            " [4.7137694]\n",
            " [4.902739 ]\n",
            " [2.7823758]]\n",
            "label [4.  4.  1.  2.5 5.5 2.5 2.5 1.  4.  4.  8.  1.  1.5 3.5 5.  3. ]\n",
            "[4. 4. 1. 2. 6. 2. 2. 1. 4. 4. 8. 1. 2. 4. 5. 3.]\n",
            "[4. 4. 2. 6. 5. 2. 2. 1. 4. 4. 5. 2. 1. 5. 5. 3.]\n",
            "the logits [[2.7823758]\n",
            " [5.6354623]\n",
            " [4.2007937]\n",
            " [1.4553757]\n",
            " [3.37885  ]\n",
            " [3.37885  ]\n",
            " [5.6479764]\n",
            " [2.1318722]\n",
            " [3.8560057]\n",
            " [2.4535918]\n",
            " [4.7646394]\n",
            " [2.7823758]\n",
            " [1.3539591]\n",
            " [4.656163 ]\n",
            " [3.8722355]\n",
            " [2.1012447]]\n",
            "label [3.  4.5 4.  1.5 3.5 3.  5.  2.  2.  2.5 4.  3.  1.  3.5 6.  2.5]\n",
            "[3. 4. 4. 2. 4. 3. 5. 2. 2. 2. 4. 3. 1. 4. 6. 2.]\n",
            "[3. 6. 4. 1. 3. 3. 6. 2. 4. 2. 5. 3. 1. 5. 4. 2.]\n",
            "the logits [[3.1604373]\n",
            " [5.524593 ]\n",
            " [4.744967 ]\n",
            " [5.5648665]\n",
            " [5.628711 ]\n",
            " [4.9508133]\n",
            " [4.0238414]\n",
            " [4.2635813]\n",
            " [4.3991017]\n",
            " [5.3947916]\n",
            " [2.8584855]\n",
            " [5.7847633]\n",
            " [4.6514416]\n",
            " [4.647722 ]\n",
            " [2.8775783]\n",
            " [2.3202627]]\n",
            "label [3.  3.5 3.5 3.5 6.5 3.5 3.5 4.  3.  4.5 2.5 5.5 4.5 3.  4.5 2.5]\n",
            "[3. 4. 4. 4. 6. 4. 4. 4. 3. 4. 2. 6. 4. 3. 4. 2.]\n",
            "[3. 6. 5. 6. 6. 5. 4. 4. 4. 5. 3. 6. 5. 5. 3. 2.]\n",
            "the logits [[5.28323  ]\n",
            " [3.1924317]]\n",
            "label [3.  4.5]\n",
            "[3. 4.]\n",
            "[5. 3.]\n",
            "  Accuracy: 0.41\n",
            "  Validation Loss: 1.47\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.72\n",
            "  Training epcoh took: 0:00:05\n",
            "\n",
            "Running Validation...\n",
            "the logits [[3.609791 ]\n",
            " [0.9706271]\n",
            " [2.7581224]\n",
            " [4.642426 ]\n",
            " [1.5384126]\n",
            " [5.1772976]\n",
            " [4.8013234]\n",
            " [3.7125468]\n",
            " [2.1318722]\n",
            " [4.2635813]\n",
            " [5.030517 ]\n",
            " [1.4553757]\n",
            " [4.400973 ]\n",
            " [5.6623096]\n",
            " [2.375461 ]\n",
            " [3.0641606]]\n",
            "label [4.  1.  3.5 3.  2.5 2.  6.  5.5 2.  4.  5.  1.5 6.5 5.  2.5 4. ]\n",
            "[4. 1. 4. 3. 2. 2. 6. 6. 2. 4. 5. 2. 6. 5. 2. 4.]\n",
            "[4. 1. 3. 5. 2. 5. 5. 4. 2. 4. 5. 1. 4. 6. 2. 3.]\n",
            "the logits [[3.8311296]\n",
            " [5.4108567]\n",
            " [2.793728 ]\n",
            " [3.7803195]\n",
            " [2.3469794]\n",
            " [5.8129783]\n",
            " [1.5384126]\n",
            " [5.1003704]\n",
            " [4.6387434]\n",
            " [4.173278 ]\n",
            " [5.184827 ]\n",
            " [5.1445985]\n",
            " [5.1961374]\n",
            " [5.529098 ]\n",
            " [2.3469794]\n",
            " [4.2437944]]\n",
            "label [4.  4.  3.  3.5 2.5 4.5 1.5 8.  5.  4.  4.5 4.  4.  6.  2.5 5. ]\n",
            "[4. 4. 3. 4. 2. 4. 2. 8. 5. 4. 4. 4. 4. 6. 2. 5.]\n",
            "[4. 5. 3. 4. 2. 6. 2. 5. 5. 4. 5. 5. 5. 6. 2. 4.]\n",
            "the logits [[5.2560706]\n",
            " [2.1012447]\n",
            " [2.0855057]\n",
            " [4.2635813]\n",
            " [5.333635 ]\n",
            " [4.2437944]\n",
            " [3.0745964]\n",
            " [1.0560193]\n",
            " [2.7823758]\n",
            " [5.4462743]\n",
            " [5.125124 ]\n",
            " [3.288515 ]\n",
            " [4.538252 ]\n",
            " [5.7403083]\n",
            " [4.2635813]\n",
            " [5.1501675]]\n",
            "label [4.  2.5 2.  4.  5.  5.5 2.5 1.  3.  6.  4.5 3.  4.  5.  4.  3. ]\n",
            "[4. 2. 2. 4. 5. 6. 2. 1. 3. 6. 4. 3. 4. 5. 4. 3.]\n",
            "[5. 2. 2. 4. 5. 4. 3. 1. 3. 5. 5. 3. 5. 6. 4. 5.]\n",
            "the logits [[3.8995864]\n",
            " [3.7014825]\n",
            " [2.910807 ]\n",
            " [4.066693 ]\n",
            " [5.605818 ]\n",
            " [2.3204975]\n",
            " [2.9307563]\n",
            " [5.6870008]\n",
            " [1.220434 ]\n",
            " [5.7410555]\n",
            " [3.1930254]\n",
            " [1.4553757]\n",
            " [4.7886677]\n",
            " [2.6110704]\n",
            " [5.6839666]\n",
            " [4.2635813]]\n",
            "label [6.  2.  3.  3.5 3.5 2.5 2.5 7.  1.  4.  4.  1.5 6.5 5.  7.  4. ]\n",
            "[6. 2. 3. 4. 4. 2. 2. 7. 1. 4. 4. 2. 6. 5. 7. 4.]\n",
            "[4. 4. 3. 4. 6. 2. 3. 6. 1. 6. 3. 1. 5. 3. 6. 4.]\n",
            "the logits [[4.42121  ]\n",
            " [4.2635813]\n",
            " [1.967767 ]\n",
            " [5.601151 ]\n",
            " [5.4462743]\n",
            " [1.77587  ]\n",
            " [2.2674165]\n",
            " [1.0118765]\n",
            " [4.202923 ]\n",
            " [4.2635813]\n",
            " [5.473537 ]\n",
            " [1.5653011]\n",
            " [1.4553757]\n",
            " [4.7137694]\n",
            " [4.902739 ]\n",
            " [2.7823758]]\n",
            "label [4.  4.  1.  2.5 5.5 2.5 2.5 1.  4.  4.  8.  1.  1.5 3.5 5.  3. ]\n",
            "[4. 4. 1. 2. 6. 2. 2. 1. 4. 4. 8. 1. 2. 4. 5. 3.]\n",
            "[4. 4. 2. 6. 5. 2. 2. 1. 4. 4. 5. 2. 1. 5. 5. 3.]\n",
            "the logits [[2.7823758]\n",
            " [5.6354623]\n",
            " [4.2007937]\n",
            " [1.4553757]\n",
            " [3.37885  ]\n",
            " [3.37885  ]\n",
            " [5.6479764]\n",
            " [2.1318722]\n",
            " [3.8560057]\n",
            " [2.4535918]\n",
            " [4.7646394]\n",
            " [2.7823758]\n",
            " [1.3539591]\n",
            " [4.656163 ]\n",
            " [3.8722355]\n",
            " [2.1012447]]\n",
            "label [3.  4.5 4.  1.5 3.5 3.  5.  2.  2.  2.5 4.  3.  1.  3.5 6.  2.5]\n",
            "[3. 4. 4. 2. 4. 3. 5. 2. 2. 2. 4. 3. 1. 4. 6. 2.]\n",
            "[3. 6. 4. 1. 3. 3. 6. 2. 4. 2. 5. 3. 1. 5. 4. 2.]\n",
            "the logits [[3.1604373]\n",
            " [5.524593 ]\n",
            " [4.744967 ]\n",
            " [5.5648665]\n",
            " [5.628711 ]\n",
            " [4.9508133]\n",
            " [4.0238414]\n",
            " [4.2635813]\n",
            " [4.3991017]\n",
            " [5.3947916]\n",
            " [2.8584855]\n",
            " [5.7847633]\n",
            " [4.6514416]\n",
            " [4.647722 ]\n",
            " [2.8775783]\n",
            " [2.3202627]]\n",
            "label [3.  3.5 3.5 3.5 6.5 3.5 3.5 4.  3.  4.5 2.5 5.5 4.5 3.  4.5 2.5]\n",
            "[3. 4. 4. 4. 6. 4. 4. 4. 3. 4. 2. 6. 4. 3. 4. 2.]\n",
            "[3. 6. 5. 6. 6. 5. 4. 4. 4. 5. 3. 6. 5. 5. 3. 2.]\n",
            "the logits [[5.28323  ]\n",
            " [3.1924317]]\n",
            "label [3.  4.5]\n",
            "[3. 4.]\n",
            "[5. 3.]\n",
            "  Accuracy: 0.41\n",
            "  Validation Loss: 1.47\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:21 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-941Q_ow8GFg",
        "outputId": "d2db8054-35cb-4dae-f652-465d8b160b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.74</td>\n",
              "      <td>1.47</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0:00:05</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.59</td>\n",
              "      <td>1.47</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0:00:05</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.55</td>\n",
              "      <td>1.47</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0:00:05</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.72</td>\n",
              "      <td>1.47</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0:00:05</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.74         1.47           0.41       0:00:05         0:00:00\n",
              "2               0.59         1.47           0.41       0:00:05         0:00:00\n",
              "3               0.55         1.47           0.41       0:00:05         0:00:00\n",
              "4               0.72         1.47           0.41       0:00:05         0:00:00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkDPCCac2DkQ",
        "outputId": "cb4ef393-0b1c-44d5-b113-b82e1bfd9332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfORi6UYA72B"
      },
      "source": [
        "#testing model score with a sentence\n",
        "answer=\"Parachute decreasing the speed while jumping from flight\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pn9-IsRAfMq"
      },
      "source": [
        "encoded_ans=tokenizer.encode_plus(answer,\n",
        "                                  max_length=15,\n",
        "                                  add_special_tokens=True,\n",
        "                                  pad_to_max_length=True,\n",
        "                                  return_attention_mask=True,\n",
        "                                  return_tensors='pt',\n",
        "                                  truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym3uhMW_CIN0",
        "outputId": "4f087ff1-d7f8-4e7e-8fe6-016b49cc71d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "encoded_ans.keys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BatchEncoding.keys of {'input_ids': tensor([[  101, 13561, 16922,  1996,  3177,  2096,  8660,  2013,  3462,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODCeyqHrBy8Z"
      },
      "source": [
        "input_ids=encoded_ans['input_ids'].to(device)\n",
        "attention_mask=encoded_ans['attention_mask'].to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgqmpRPRCRR9"
      },
      "source": [
        "output=model(input_ids,attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bQxoivYCm5o",
        "outputId": "0e608845-1f4e-4cc4-8e34-51a475fe719a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5.5779]], device='cuda:0', grad_fn=<AddmmBackward>),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk4LJgbaikgu",
        "outputId": "c859a07d-0dc3-4169-a3ac-d0d3083892ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#list(output)\n",
        "score=output[0][0].item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.577868938446045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Y8z8ajCz0H",
        "outputId": "bdbbd4bf-1334-4f77-dd51-2785e5cc6ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f'The user answer is: {answer}')\n",
        "print(f'The calculated score is: {score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The user answer is: Parachute decreasing the speed while jumping from flight\n",
            "The calculated score is: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmko8wZgDgWA"
      },
      "source": [
        "#saving the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnjb9tXTELQ9",
        "outputId": "ed14aa94-367b-4a85-935b-6c024a775cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQJAagPJ8LCD",
        "outputId": "20849a08-2bba-45c1-af7c-6d8a80fb0a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#loading the saved model\n",
        "from transformers import *\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}