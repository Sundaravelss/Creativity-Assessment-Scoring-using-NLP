{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creativity assessment scoring by Fine tuning Camembert- French.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee9007a83b6b4a609922983ece28ab32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fa749e2346cd481a94ef8716cf9cd0e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c55f5759790a4f068af240dddb3efd09",
              "IPY_MODEL_b97eec88ab4a4681a24be771c923737d"
            ]
          }
        },
        "fa749e2346cd481a94ef8716cf9cd0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c55f5759790a4f068af240dddb3efd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8558d5c0f19496d873816adbae88ac5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf62e8f19e634b7dab07348625685210"
          }
        },
        "b97eec88ab4a4681a24be771c923737d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_399cedfa74df4bf0813db1e1fe2df6e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 811k/811k [00:57&lt;00:00, 14.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45897a4000b6488b9cace3c67f71480e"
          }
        },
        "d8558d5c0f19496d873816adbae88ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf62e8f19e634b7dab07348625685210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "399cedfa74df4bf0813db1e1fe2df6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45897a4000b6488b9cace3c67f71480e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03b2247a57e64d56b0f46aff884edc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b707274a5fef405da290a5aa5aeaca7c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_644bc0f384914cab9cd54795c1a1f9c3",
              "IPY_MODEL_da84a3a5db474e19b874d38bf2ae45cb"
            ]
          }
        },
        "b707274a5fef405da290a5aa5aeaca7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "644bc0f384914cab9cd54795c1a1f9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_769f9a505bfc4333947968047ea58dc4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05c00e5c6ec1465ca491c8d351e94b8a"
          }
        },
        "da84a3a5db474e19b874d38bf2ae45cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d5e4c02191d4ea78cb1c7bdb7910491",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 508/508 [00:00&lt;00:00, 747B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5abcb52a1a9646f68bdafc8824bf91b4"
          }
        },
        "769f9a505bfc4333947968047ea58dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05c00e5c6ec1465ca491c8d351e94b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d5e4c02191d4ea78cb1c7bdb7910491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5abcb52a1a9646f68bdafc8824bf91b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b208093744ac4921a3c4c62e697a4498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c777df1b6e1949c3a2dd87be9e84ae0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f99edce9a38486fbf9d87b205639f7f",
              "IPY_MODEL_e4efb42e14c64e9fbe0183439bcfe086"
            ]
          }
        },
        "c777df1b6e1949c3a2dd87be9e84ae0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f99edce9a38486fbf9d87b205639f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4eaec377828455fb6bf7c867c08af4e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445032417,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445032417,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c029c6cfd974d778935225edb4de978"
          }
        },
        "e4efb42e14c64e9fbe0183439bcfe086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e732dbb5070044a8aed856286b9473dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:20&lt;00:00, 22.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32a002e404e54616890bef77a55034de"
          }
        },
        "f4eaec377828455fb6bf7c867c08af4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c029c6cfd974d778935225edb4de978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e732dbb5070044a8aed856286b9473dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32a002e404e54616890bef77a55034de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sundaravelss/Creativity-Assessment-Scoring-using-NLP/blob/main/Creativity_assessment_scoring_by_Fine_tuning_Camembert_French.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEOSMl9wrIpY",
        "outputId": "dc1b2d17-5749-4f0b-de1f-10ac36f890ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#checking for gpu instance\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR7Cw-w4rUK4",
        "outputId": "6bb9a1dc-373f-43c8-85f8-354d91c3c48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#setting device to use gpu\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhLu5xGUrZea",
        "outputId": "d4ce865d-a553-4b6f-c529-74841536f24c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 15.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 19.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=af0daa582bdc2043bd239a883f995272710becdac0cc5e0ad70c646d36ffd35b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR1erIKwrh6u",
        "outputId": "e6fcb5e4-3684-4a9a-db8e-28fd1d662194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "#loading the dataset\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_excel('./final_data_french.xlsx')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Recueillir de l’eau</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>parachute</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Protéger du soleil.</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>contre la pluie</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>protéger de la pluie</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134</th>\n",
              "      <td>1134</td>\n",
              "      <td>porte-chapeau</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>1135</td>\n",
              "      <td>cerf volant</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1136</th>\n",
              "      <td>1136</td>\n",
              "      <td>decoration murale</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1137</th>\n",
              "      <td>1137</td>\n",
              "      <td>perche</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1138</th>\n",
              "      <td>1138</td>\n",
              "      <td>canne a peche</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1139 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0              sentence  label\n",
              "0              0   Recueillir de l’eau    3.0\n",
              "1              1             parachute    4.0\n",
              "2              2   Protéger du soleil.    2.0\n",
              "3              3       contre la pluie    1.0\n",
              "4              4  protéger de la pluie    1.0\n",
              "...          ...                   ...    ...\n",
              "1134        1134         porte-chapeau    4.0\n",
              "1135        1135           cerf volant    9.0\n",
              "1136        1136     decoration murale    4.0\n",
              "1137        1137                perche    4.0\n",
              "1138        1138         canne a peche    4.0\n",
              "\n",
              "[1139 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2KECujmtkuG",
        "outputId": "ad237938-68da-45eb-9962-5dcd9542d2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "#counting number of unique labels(scores here)\n",
        "print('no. of unique values:',len(df.label.unique()))\n",
        "df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of unique values: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0    178\n",
              "3.0    173\n",
              "3.5    113\n",
              "5.0    100\n",
              "2.5     92\n",
              "4.5     87\n",
              "2.0     70\n",
              "6.0     68\n",
              "1.5     60\n",
              "1.0     60\n",
              "5.5     45\n",
              "6.5     34\n",
              "7.0     32\n",
              "8.0     14\n",
              "7.5     10\n",
              "8.5      2\n",
              "9.0      1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q617knh-4ARi"
      },
      "source": [
        "#Number of classes\n",
        "#df.label.value_counts(),len(df.label.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qazuug0qr8pb"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHxYtyaz90ux",
        "outputId": "9cabe1f1-00f0-4aea-ff8a-bc8700e34165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 4., 2., ..., 4., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_xmuFfPsIK8",
        "outputId": "9d16ccfc-4a0b-413b-866d-f6f895d5ff5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ee9007a83b6b4a609922983ece28ab32",
            "fa749e2346cd481a94ef8716cf9cd0e1",
            "c55f5759790a4f068af240dddb3efd09",
            "b97eec88ab4a4681a24be771c923737d",
            "d8558d5c0f19496d873816adbae88ac5",
            "cf62e8f19e634b7dab07348625685210",
            "399cedfa74df4bf0813db1e1fe2df6e9",
            "45897a4000b6488b9cace3c67f71480e"
          ]
        }
      },
      "source": [
        "from transformers import CamembertTokenizer\n",
        "\n",
        "from transformers import *\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading Camembert tokenizer...')\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Camembert tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee9007a83b6b4a609922983ece28ab32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=810912.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrPmJpHcsN3Q",
        "outputId": "1e3ab33d-fb1b-4900-8041-953678514ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Recueillir de l’eau\n",
            "Tokenized:  ['▁Recueil', 'lir', '▁de', '▁l', '’', 'eau']\n",
            "Token IDs:  [27497, 14925, 8, 17, 12, 252]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmOfWnqfsmic",
        "outputId": "2c766818-bf9a-447e-96ef-784f83a6945d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_len = 0\n",
        "length=[]\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    #print(len(input_ids))\n",
        "    length.append(len(input_ids))\n",
        "    # Update the maximum sentence tokens.\n",
        "    max_len = max(max_len,len(input_ids))\n",
        "\n",
        "print('Max sentence tokens: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence tokens:  63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWGwW9CT8nMq",
        "outputId": "fca5a7c5-d6a9-4173-ec6b-de182c75e747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.sentence.map(len).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMFwwIZWYza",
        "outputId": "812cb268-66da-45b7-888f-1dc81501c98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f232edb0a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUAiVeKs-UjH",
        "outputId": "ce5efbf4-83e0-423f-c75f-4ee9fe3c06a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "for sent in sentences:\n",
        "  if(len(sent)==297):\n",
        "    print('The sentence which has the maximum number of words is:',sent, len(sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentence which has the maximum number of words is: petit récupérateur de pluie en renversant le parapluie et lui ajoutant un tuyau d'utilisation (possibilité d'en empiler en cascade pour augmenter la contenance). Accessoire de sport pour travailler la souplesse (utiliser l'anse pour par exemple attraper le pied et permettre de tirer sur la jambe) 297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgkvFuHl-cWa",
        "outputId": "88ec2d5d-deb1-4d55-fce7-daea3bc8dd5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, add_special_tokens = True, max_length = 20,pad_to_max_length = True,return_attention_mask = True, return_tensors = 'pt',truncation=True )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Recueillir de l’eau\n",
            "Token IDs: tensor([    5, 27497, 14925,     8,    17,    12,   252,     6,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuJIPvY6AQcS",
        "outputId": "f533d364-1bda-475a-d5be-941a89bebc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels = torch.tensor(labels,dtype=torch.float)\n",
        "labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_OuihSeSRUo",
        "outputId": "29788d9d-a66e-4071-bf0c-0b2bb910f89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "attention_masks[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88G6xnjQB3VG",
        "outputId": "deccb6ca-d681-4b5f-af5a-579547e8d3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,025 training samples\n",
            "  114 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytOwgnsvRpt5"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#hyperparameter 16 or 32\n",
        "batch_size = 16\n",
        "#dataloader\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size )\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF-djsMeU55k",
        "outputId": "95d0f866-943f-409c-f3a0-c591aeee5b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03b2247a57e64d56b0f46aff884edc75",
            "b707274a5fef405da290a5aa5aeaca7c",
            "644bc0f384914cab9cd54795c1a1f9c3",
            "da84a3a5db474e19b874d38bf2ae45cb",
            "769f9a505bfc4333947968047ea58dc4",
            "05c00e5c6ec1465ca491c8d351e94b8a",
            "3d5e4c02191d4ea78cb1c7bdb7910491",
            "5abcb52a1a9646f68bdafc8824bf91b4",
            "b208093744ac4921a3c4c62e697a4498",
            "c777df1b6e1949c3a2dd87be9e84ae0f",
            "4f99edce9a38486fbf9d87b205639f7f",
            "e4efb42e14c64e9fbe0183439bcfe086",
            "f4eaec377828455fb6bf7c867c08af4e",
            "0c029c6cfd974d778935225edb4de978",
            "e732dbb5070044a8aed856286b9473dc",
            "32a002e404e54616890bef77a55034de"
          ]
        }
      },
      "source": [
        "from transformers import CamembertForSequenceClassification, AdamW, CamembertConfig\n",
        "\n",
        "#load camembert model\n",
        "model = CamembertForSequenceClassification.from_pretrained(\n",
        "    \"camembert-base\",\n",
        "    num_labels = 17, # The number of output labels--10 (1 to 9) or --17 (if 0.5 is to be included.e.g,1,1.5,2..)\n",
        "    #num_labels=1 for regression task\n",
        "                       \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03b2247a57e64d56b0f46aff884edc75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b208093744ac4921a3c4c62e697a4498",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445032417.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiVAybuBU7b8"
      },
      "source": [
        "#optimizing with adamw\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSHI_fXkqksx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM38VX73rYGc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "'''def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)'''\n",
        "\n",
        "def flat_accuracy(preds,labels):\n",
        "  labels_flat=labels.flatten()\n",
        "  labels_flat=np.round(labels_flat)\n",
        "  preds_flat=preds.flatten()\n",
        "  preds_flat=np.round(preds_flat)\n",
        "  #print(labels_flat)\n",
        "  #print(preds_flat)\n",
        "  length=len(labels_flat)\n",
        "  accuracy=np.sum(preds_flat==labels_flat)/length\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE4l1vZ7u_4z"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECON08Faz3p5",
        "outputId": "f8a3eb56-fce9-4ff4-86e7-c2c8d28d19cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "for batch in train_dataloader:\n",
        "  print(batch[0],batch[2])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[    5,  3236,  6688,  3990,  2560,  2777,     6,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5, 12421,  8053,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5, 16047,     6,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,  5718, 24244,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,    28,  2466,    22,  2482,    13,  3441,     6,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5, 24229,   621, 16279,    73,   650,     6,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,    84,  3533,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,  1029,  4883,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,    98,    21,  7223,   185,  3003,     6,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5, 20614,  2026,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,    18,  1146,  8444,     8,  3377,     6,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5, 11179,    16,   950,     6,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,  8247,     6,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,   444, 20682,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5, 17793,  5345,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    5,    28, 11541,     6,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]]) tensor([8.0000, 3.0000, 2.5000, 3.5000, 5.5000, 8.0000, 2.0000, 2.0000, 3.0000,\n",
            "        5.0000, 7.0000, 1.5000, 3.0000, 4.0000, 9.0000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZQqG-LQvgZU",
        "outputId": "7d0d435e-ef02-4917-a9c2-c3434e85d62b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#CUDA_LAUNCH_BLOCKING=\"1\"\n",
        "import random\n",
        "import numpy as np\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    #Training\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0 to prevent exploding gradient\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # validation\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "      \n",
        "        #input ids\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        #attention mask\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        #labels\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 10.40\n",
            "  Training epcoh took: 0:00:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.21\n",
            "  Validation Loss: 5.60\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 3.89\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.27\n",
            "  Validation Loss: 2.88\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 2.55\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.33\n",
            "  Validation Loss: 2.36\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 2.03\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.37\n",
            "  Validation Loss: 1.77\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 5 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 1.54\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.43\n",
            "  Validation Loss: 1.45\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 6 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 1.35\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.42\n",
            "  Validation Loss: 1.32\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 7 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 1.14\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.42\n",
            "  Validation Loss: 1.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 8 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 1.11\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.45\n",
            "  Validation Loss: 1.21\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:35 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-941Q_ow8GFg",
        "outputId": "e7fcf340-0de2-42f9-d9ca-390212c6937f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.40</td>\n",
              "      <td>5.60</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0:00:05</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.89</td>\n",
              "      <td>2.88</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.55</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.03</td>\n",
              "      <td>1.77</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.54</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.35</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.14</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.11</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1              10.40         5.60           0.21       0:00:05         0:00:00\n",
              "2               3.89         2.88           0.27       0:00:04         0:00:00\n",
              "3               2.55         2.36           0.33       0:00:04         0:00:00\n",
              "4               2.03         1.77           0.37       0:00:04         0:00:00\n",
              "5               1.54         1.45           0.43       0:00:04         0:00:00\n",
              "6               1.35         1.32           0.42       0:00:04         0:00:00\n",
              "7               1.14         1.19           0.42       0:00:04         0:00:00\n",
              "8               1.11         1.21           0.45       0:00:04         0:00:00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkDPCCac2DkQ",
        "outputId": "3a635833-cb85-41a7-aed7-0c6806045f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfORi6UYA72B"
      },
      "source": [
        "answer=\"Le tenir dans le sens inverse pour porter des choses à l'exterieur\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pn9-IsRAfMq"
      },
      "source": [
        "encoded_ans=tokenizer.encode_plus(answer,\n",
        "                                  max_length=20,\n",
        "                                  add_special_tokens=True,\n",
        "                                  pad_to_max_length=True,\n",
        "                                  return_attention_mask=True,\n",
        "                                  return_tensors='pt',\n",
        "                                  truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym3uhMW_CIN0",
        "outputId": "5cca3c79-fa44-4edb-e2a6-e4e9fa5236ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "encoded_ans.keys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BatchEncoding.keys of {'input_ids': tensor([[    5,    54,  1852,    29,    16,   437, 10628,    24,  1499,    20,\n",
              "           541,    15,    17,    11,   850, 13355,   297,     6,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODCeyqHrBy8Z"
      },
      "source": [
        "input_ids=encoded_ans['input_ids'].to(device)\n",
        "attention_mask=encoded_ans['attention_mask'].to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgqmpRPRCRR9"
      },
      "source": [
        "output=model(input_ids,attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bQxoivYCm5o",
        "outputId": "114af81f-6901-4ea9-e22c-4e2ce9af71bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[4.7874]], device='cuda:0', grad_fn=<AddmmBackward>),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULE6nWW1CgX8"
      },
      "source": [
        "score=output[0][0].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFPT11EUCqP3"
      },
      "source": [
        "#_,prediction=torch.max(output[0],dim=1)\n",
        "#prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Y8z8ajCz0H",
        "outputId": "4509434e-019b-41d6-a8aa-9e5c78c8e912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f'The user answer is: {answer}')\n",
        "print(f'The calculated score is: {score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The user answer is: Le tenir dans le sens inverse pour porter des choses à l'exterieur\n",
            "The calculated score is: 4.787374496459961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmko8wZgDgWA",
        "outputId": "f11eb94c-f896-463a-d5c0-24e5e77447cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#saving model\n",
        "import os\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/sentencepiece.bpe.model',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnjb9tXTELQ9",
        "outputId": "22fef894-9213-4f6a-e19e-e25d0f374477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#load trained model\n",
        "from transformers import *\n",
        "\n",
        "model = CamembertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = CamembertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzpuLdF0Z44A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}